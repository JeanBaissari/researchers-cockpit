{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Walk-Forward Validation\n",
        "\n",
        "Perform walk-forward analysis to validate strategy robustness.\n",
        "\n",
        "**Version**: v1.11.0  \n",
        "**Architecture**: Modular (lib/validate/, lib/paths/, lib/config/)\n",
        "\n",
        "## Configuration\n",
        "\n",
        "Set the strategy name and walk-forward parameters below.\n",
        "\n",
        "**Note**: This notebook uses the v1.11.0 modular architecture. All imports use canonical paths from `lib/` packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "strategy_name = 'spy_sma_cross'  # Change to your strategy\n",
        "start_date = '2020-01-01'\n",
        "end_date = None  # None = today\n",
        "train_period = 252  # Trading days for training (1 year)\n",
        "test_period = 63    # Trading days for testing (1 quarter)\n",
        "step_size = 63      # Step size between windows (1 quarter)\n",
        "objective = 'sharpe'  # Objective metric for optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Standard library imports\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Third-party imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Local imports - lib modules (v1.11.0 modular architecture)\n",
        "# Validation modules provide walk-forward and Monte Carlo analysis\n",
        "from lib.paths import get_project_root, get_results_dir\n",
        "from lib.validate import walk_forward, calculate_walk_forward_efficiency\n",
        "from lib.config import load_strategy_params\n",
        "from lib.validation import validate_bundle\n",
        "from lib.calendars import get_calendar_for_asset_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-validation Checks\n",
        "print(\"Pre-walk-forward validation:\")\n",
        "try:\n",
        "    # Load strategy to get asset class\n",
        "    params = load_strategy_params(strategy_name)\n",
        "    asset_class = params.get('strategy', {}).get('asset_class', 'equities')\n",
        "    calendar = get_calendar_for_asset_class(asset_class)\n",
        "    \n",
        "    print(f\"  ✓ Strategy: {strategy_name}\")\n",
        "    print(f\"  ✓ Asset Class: {asset_class}\")\n",
        "    print(f\"  ✓ Calendar: {calendar}\")\n",
        "    \n",
        "    # Validate date range\n",
        "    if end_date is None:\n",
        "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    \n",
        "    print(f\"  ✓ Date Range: {start_date} to {end_date}\")\n",
        "    print(f\"  ✓ Train Period: {train_period} days\")\n",
        "    print(f\"  ✓ Test Period: {test_period} days\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"  ✗ Validation error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Run walk-forward analysis\n",
        "print(f\"\\nRunning walk-forward analysis for {strategy_name}...\")\n",
        "print(f\"Date range: {start_date} to {end_date or 'today'}\")\n",
        "print(f\"Train period: {train_period} days\")\n",
        "print(f\"Test period: {test_period} days\")\n",
        "print(f\"Step size: {step_size} days\")\n",
        "\n",
        "try:\n",
        "    results = walk_forward(\n",
        "        strategy_name=strategy_name,\n",
        "        start_date=start_date,\n",
        "        end_date=end_date,\n",
        "        train_period=train_period,\n",
        "        test_period=test_period,\n",
        "        objective=objective\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n✓ Walk-forward analysis complete\")\n",
        "    if 'out_sample_results' in results:\n",
        "        print(f\"  Periods: {len(results['out_sample_results'])}\")\n",
        "    elif 'windows' in results:\n",
        "        print(f\"  Windows: {len(results['windows'])}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Walk-forward analysis failed: {e}\")\n",
        "    print(f\"  Check that strategy exists and date range is valid\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display walk-forward validation results\n",
        "if results:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"WALK-FORWARD VALIDATION RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Handle both old and new result formats\n",
        "    if 'robustness' in results:\n",
        "        # Old format with robustness dict\n",
        "        robustness = results['robustness']\n",
        "        print(\"\\nRobustness Metrics:\")\n",
        "        print(f\"  Walk-Forward Efficiency: {robustness.get('efficiency', 0):.3f}\")\n",
        "        print(f\"  Consistency: {robustness.get('consistency', 0):.2%}\")\n",
        "        print(f\"  Avg IS Sharpe: {robustness.get('avg_is_sharpe', 0):.3f}\")\n",
        "        print(f\"  Avg OOS Sharpe: {robustness.get('avg_oos_sharpe', 0):.3f}\")\n",
        "        print(f\"  Std OOS Sharpe: {robustness.get('std_oos_sharpe', 0):.3f}\")\n",
        "        print(f\"  Number of Periods: {robustness.get('n_periods', 0)}\")\n",
        "    \n",
        "    # Overall statistics (new format)\n",
        "    if 'summary' in results:\n",
        "        summary = results['summary']\n",
        "        print(\"\\nOverall Summary:\")\n",
        "        print(f\"  Total Windows: {summary.get('total_windows', 0)}\")\n",
        "        print(f\"  Average Test Return: {summary.get('avg_test_return', 0):.2%}\")\n",
        "        print(f\"  Average Test Sharpe: {summary.get('avg_test_sharpe', 0):.3f}\")\n",
        "        print(f\"  Consistency: {summary.get('consistency', 0):.2%}\")\n",
        "    \n",
        "    # Window-by-window results\n",
        "    if 'windows' in results and len(results['windows']) > 0:\n",
        "        print(\"\\nWindow-by-Window Results:\")\n",
        "        windows_df = pd.DataFrame(results['windows'])\n",
        "        \n",
        "        # Display key metrics\n",
        "        display_cols = ['train_start', 'test_start', 'test_end', \n",
        "                       'test_return', 'test_sharpe', 'test_max_dd']\n",
        "        available_cols = [col for col in display_cols if col in windows_df.columns]\n",
        "        \n",
        "        if available_cols:\n",
        "            print(windows_df[available_cols].to_string(index=False))\n",
        "        \n",
        "        # Calculate efficiency if available\n",
        "        try:\n",
        "            efficiency = calculate_walk_forward_efficiency(results)\n",
        "            print(f\"\\nWalk-Forward Efficiency: {efficiency:.3f}\")\n",
        "            if efficiency > 0.5:\n",
        "                print(\"  ✓ Good efficiency (OOS performance > 50% of IS)\")\n",
        "            elif efficiency > 0.3:\n",
        "                print(\"  ⚠ Moderate efficiency (OOS performance 30-50% of IS)\")\n",
        "            else:\n",
        "                print(\"  ✗ Low efficiency (OOS performance < 30% of IS)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Could not calculate efficiency: {e}\")\n",
        "    \n",
        "    # Save results\n",
        "    results_dir = get_results_dir() / strategy_name / 'latest'\n",
        "    if results_dir.exists():\n",
        "        results_file = results_dir / 'walkforward_results.json'\n",
        "        try:\n",
        "            # Convert to JSON-serializable format\n",
        "            results_serializable = {\n",
        "                'summary': results.get('summary', {}),\n",
        "                'windows': [\n",
        "                    {k: (str(v) if isinstance(v, pd.Timestamp) else v) \n",
        "                     for k, v in window.items()}\n",
        "                    for window in results.get('windows', [])\n",
        "                ]\n",
        "            }\n",
        "            \n",
        "            with open(results_file, 'w') as f:\n",
        "                json.dump(results_serializable, f, indent=2, default=str)\n",
        "            \n",
        "            print(f\"\\n✓ Results saved to: {results_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Could not save results: {e}\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"⚠ No results to display\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display IS vs OOS comparison (if available in old format)\n",
        "if results and 'in_sample_results' in results and 'out_sample_results' in results:\n",
        "    is_df = results['in_sample_results']\n",
        "    oos_df = results['out_sample_results']\n",
        "    \n",
        "    print(\"\\nIn-Sample vs Out-of-Sample Comparison:\")\n",
        "    comparison = pd.DataFrame({\n",
        "        'Period': range(1, len(is_df) + 1),\n",
        "        'IS Sharpe': is_df['sharpe'].values,\n",
        "        'OOS Sharpe': oos_df['sharpe'].values,\n",
        "    })\n",
        "    print(comparison.to_string(index=False))\n",
        "elif results and 'windows' in results:\n",
        "    # New format: extract from windows\n",
        "    windows_df = pd.DataFrame(results['windows'])\n",
        "    if 'train_sharpe' in windows_df.columns and 'test_sharpe' in windows_df.columns:\n",
        "        print(\"\\nIn-Sample vs Out-of-Sample Comparison:\")\n",
        "        comparison = pd.DataFrame({\n",
        "            'Window': range(1, len(windows_df) + 1),\n",
        "            'IS Sharpe': windows_df['train_sharpe'].values,\n",
        "            'OOS Sharpe': windows_df['test_sharpe'].values,\n",
        "        })\n",
        "        print(comparison.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize walk-forward results\n",
        "if results and 'windows' in results and len(results['windows']) > 0:\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        \n",
        "        windows_df = pd.DataFrame(results['windows'])\n",
        "        \n",
        "        if 'test_return' in windows_df.columns and 'test_sharpe' in windows_df.columns:\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "            \n",
        "            # Plot test returns\n",
        "            ax1.bar(range(len(windows_df)), windows_df['test_return'], \n",
        "                   color=['green' if x > 0 else 'red' for x in windows_df['test_return']])\n",
        "            ax1.set_title('Walk-Forward Test Returns by Window', fontsize=14, fontweight='bold')\n",
        "            ax1.set_xlabel('Window Number')\n",
        "            ax1.set_ylabel('Test Return')\n",
        "            ax1.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Plot test Sharpe ratios\n",
        "            ax2.bar(range(len(windows_df)), windows_df['test_sharpe'],\n",
        "                   color=['green' if x > 0 else 'red' for x in windows_df['test_sharpe']])\n",
        "            ax2.set_title('Walk-Forward Test Sharpe Ratios by Window', fontsize=14, fontweight='bold')\n",
        "            ax2.set_xlabel('Window Number')\n",
        "            ax2.set_ylabel('Test Sharpe Ratio')\n",
        "            ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"⚠ Required columns not found for visualization\")\n",
        "            print(f\"  Available columns: {list(windows_df.columns)}\")\n",
        "            \n",
        "    except ImportError:\n",
        "        print(\"⚠ Matplotlib not available for visualization\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Visualization error: {e}\")\n",
        "elif results and 'out_sample_results' in results:\n",
        "    # Old format: try to visualize from out_sample_results\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        \n",
        "        oos_df = results['out_sample_results']\n",
        "        if 'sharpe' in oos_df.columns:\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "            ax.bar(range(len(oos_df)), oos_df['sharpe'],\n",
        "                   color=['green' if x > 0 else 'red' for x in oos_df['sharpe']])\n",
        "            ax.set_title('Walk-Forward Test Sharpe Ratios by Period', fontsize=14, fontweight='bold')\n",
        "            ax.set_xlabel('Period Number')\n",
        "            ax.set_ylabel('Test Sharpe Ratio')\n",
        "            ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    except ImportError:\n",
        "        print(\"⚠ Matplotlib not available for visualization\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Visualization error: {e}\")\n",
        "else:\n",
        "    print(\"⚠ No visualization data available\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
