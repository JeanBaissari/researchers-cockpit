---
description: Validation methods - walk_forward, monte_carlo, overfit probability, walk-forward efficiency
globs: lib/validate/**/*.py
alwaysApply: false
---

# Validation Methods Patterns

## Purpose
Define patterns for strategy validation using `lib/validate/` modules, including walk-forward analysis, Monte Carlo simulation, overfit probability, and walk-forward efficiency.

## Walk-Forward Analysis

### Use walk_forward() Function
Always use `lib.validate.walk_forward()` for rolling train/test validation.

```python
# ✅ GOOD - Use walk_forward()
from lib.validate import walk_forward

results = walk_forward(
    strategy_name='btc_sma_cross',
    start_date='2018-01-01',
    end_date='2024-01-01',
    train_period=252,  # 1 year
    test_period=63,     # 3 months
    objective='sharpe'
)

# Check efficiency
efficiency = results['robustness']['efficiency']
consistency = results['robustness']['consistency']

if efficiency < 0.5:
    print("Warning: Low walk-forward efficiency")

# ❌ BAD - Manual walk-forward
for period in periods:
    # Manual train/test split and backtest...  # Don't do this!
```

### Walk-Forward Parameters

```python
# ✅ GOOD - Complete parameter specification
results = walk_forward(
    strategy_name='btc_sma_cross',
    start_date='2018-01-01',    # Required
    end_date='2024-01-01',      # Required
    train_period=252,           # Training period in days (~1 year)
    test_period=63,             # Testing period in days (~3 months)
    optimize_params={           # Optional: optimize in each period
        'strategy.fast_period': [5, 10, 15]
    },
    objective='sharpe',         # Optimization objective
    capital_base=100000,        # Optional
    bundle='yahoo_crypto_daily',  # Optional
    asset_class='crypto'       # Optional
)

# ❌ BAD - Insufficient periods
results = walk_forward(
    start_date='2023-01-01',
    end_date='2024-01-01',  # Only 1 year - not enough for walk-forward!
    train_period=252,
    test_period=63
)
```

## Monte Carlo Simulation

### Use monte_carlo() Function
Use `lib.validate.monte_carlo()` for probabilistic outcome analysis.

```python
# ✅ GOOD - Use monte_carlo()
from lib.validate import monte_carlo

mc_results = monte_carlo(
    returns=returns_series,
    n_simulations=1000,
    confidence_levels=[0.05, 0.50, 0.95],
    initial_value=100000
)

# Access confidence intervals
p5 = mc_results['confidence_intervals']['p5']
p50 = mc_results['confidence_intervals']['p50']
p95 = mc_results['confidence_intervals']['p95']

print(f"5th percentile: ${p5:,.0f}")
print(f"Median: ${p50:,.0f}")
print(f"95th percentile: ${p95:,.0f}")

# ❌ BAD - Manual Monte Carlo
import random
for _ in range(1000):
    shuffled = random.shuffle(returns)  # Incomplete simulation!
```

### Monte Carlo Parameters

```python
# ✅ GOOD - Appropriate simulation parameters
mc_results = monte_carlo(
    returns=returns_series,      # Required: daily returns
    n_simulations=1000,          # Number of simulation paths
    confidence_levels=[0.05, 0.50, 0.95],  # Percentile levels
    initial_value=100000.0      # Starting portfolio value
)

# ❌ BAD - Too few simulations
mc_results = monte_carlo(returns, n_simulations=10)  # Not enough!
```

## Overfit Probability

### Calculate Overfit Probability
Always calculate overfit probability after optimization.

```python
# ✅ GOOD - Calculate overfit probability
from lib.optimize import calculate_overfit_score

overfit_score = calculate_overfit_score(
    in_sample_metrics=is_metrics,
    out_sample_metrics=oos_metrics
)

overfit_prob = overfit_score['overfit_probability']

if overfit_prob > 0.4:
    print(f"High overfit probability: {overfit_prob:.1%}")
    print("Strategy may not generalize to new data")

# ❌ BAD - Ignore overfitting
# No overfit check after optimization!
```

## Walk-Forward Efficiency

### Check Walk-Forward Efficiency
Always check walk-forward efficiency from results.

```python
# ✅ GOOD - Check efficiency from results
results = walk_forward(...)

efficiency = results['robustness']['efficiency']
consistency = results['robustness']['consistency']

# Interpretation
if efficiency >= 0.7:
    print("Excellent: Strategy is robust")
elif efficiency >= 0.5:
    print("Acceptable: Strategy shows promise")
else:
    print("Poor: Strategy may be overfitted")

# ❌ BAD - Don't check efficiency
results = walk_forward(...)
# No efficiency check!
```

## Validation Workflow

### Complete Validation Workflow
Follow complete validation workflow: walk-forward then Monte Carlo.

```python
# ✅ GOOD - Complete validation workflow
from lib.validate import walk_forward, monte_carlo
from lib.backtest import run_backtest

# 1. Walk-forward analysis
wf_results = walk_forward(
    strategy_name='btc_sma_cross',
    start_date='2018-01-01',
    end_date='2024-01-01'
)

efficiency = wf_results['robustness']['efficiency']

# 2. If walk-forward passes, run Monte Carlo
if efficiency > 0.5:
    perf, _ = run_backtest('btc_sma_cross')
    mc_results = monte_carlo(perf['returns'].dropna())
    
    p5 = mc_results['confidence_intervals']['p5']
    if p5 > 0:
        print("Strategy validated: Ready for paper trading")

# ❌ BAD - Skip validation steps
perf, _ = run_backtest('btc_sma_cross')
# No validation!
```

## Validation Thresholds

### Use Standard Thresholds
Apply standard validation thresholds for strategy assessment.

```python
# ✅ GOOD - Apply validation thresholds
results = walk_forward(...)
efficiency = results['robustness']['efficiency']
consistency = results['robustness']['consistency']

# Standard thresholds
if efficiency >= 0.7 and consistency >= 0.7:
    status = "validated"
elif efficiency >= 0.5 and consistency >= 0.5:
    status = "testing"
else:
    status = "needs_work"

# ❌ BAD - No thresholds
results = walk_forward(...)
# No assessment criteria!
```

## Enforcement

- **Code Review**: Verify walk-forward and Monte Carlo usage
- **Efficiency Check**: Ensure walk-forward efficiency checked
- **Overfit Check**: Verify overfit probability calculated
- **Workflow Compliance**: Check complete validation workflow followed

## Related Agents

- `.claude/agents/validator.md` - Validation patterns
- `.claude/agents/optimizer.md` - Overfit detection
- `lib/validate/` - Validation module documentation
