---
description: Metrics calculation - calculate_metrics, trade metrics, rolling metrics, metric validation
globs: lib/metrics/**/*.py
alwaysApply: false
---

# Metrics Calculation Patterns

## Purpose
Define patterns for calculating performance metrics using `lib/metrics/` modules, including calculate_metrics, trade metrics, rolling metrics, and metric validation.

## Core Metrics Calculation

### Use calculate_metrics() Function
Always use `lib.metrics.calculate_metrics()` for performance metrics.

```python
# ✅ GOOD - Use calculate_metrics()
from lib.metrics import calculate_metrics

metrics = calculate_metrics(
    returns=returns_series,
    transactions=transactions_df,
    benchmark_returns=benchmark_returns,
    risk_free_rate=0.04,
    trading_days_per_year=252
)

print(f"Sharpe Ratio: {metrics['sharpe_ratio']:.2f}")
print(f"Max Drawdown: {metrics['max_drawdown']:.2%}")

# ❌ BAD - Manual metric calculation
sharpe = returns.mean() / returns.std()  # Incomplete calculation!
```

### Metrics Calculation Parameters

```python
# ✅ GOOD - Complete parameter specification
metrics = calculate_metrics(
    returns=returns_series,           # Required: returns series
    transactions=transactions_df,     # Optional: for trade metrics
    benchmark_returns=benchmark,      # Optional: for alpha/beta
    risk_free_rate=0.04,             # Annual risk-free rate
    trading_days_per_year=252,       # Trading days per year
    convert_to_percentages=True      # Convert decimals to percentages
)

# ❌ BAD - Missing required parameters
metrics = calculate_metrics()  # Missing returns!
```

## Trade Metrics

### Use calculate_trade_metrics() Function
Use `calculate_trade_metrics()` for trade-level analysis.

```python
# ✅ GOOD - Use calculate_trade_metrics()
from lib.metrics import calculate_trade_metrics

trade_metrics = calculate_trade_metrics(
    transactions=transactions_df,
    as_percentages=True
)

print(f"Win Rate: {trade_metrics['win_rate']:.1%}")
print(f"Profit Factor: {trade_metrics['profit_factor']:.2f}")
print(f"Avg Trade Return: {trade_metrics['avg_trade_return']:.2%}")

# ❌ BAD - Manual trade analysis
wins = sum(1 for t in trades if t.profit > 0)
win_rate = wins / len(trades)  # Incomplete analysis!
```

### Trade Metrics Access

```python
# ✅ GOOD - Access all trade metrics
trade_metrics = calculate_trade_metrics(transactions_df)

# Available metrics:
# - trade_count
# - win_rate
# - profit_factor
# - avg_trade_return
# - avg_win, avg_loss
# - max_win, max_loss
# - max_consecutive_losses
# - avg_trade_duration
# - trades_per_month

# ❌ BAD - Calculate only one metric
win_rate = len(winning_trades) / len(all_trades)  # Missing other metrics!
```

## Rolling Metrics

### Use calculate_rolling_metrics() Function
Use `calculate_rolling_metrics()` for time-series metric analysis.

```python
# ✅ GOOD - Use calculate_rolling_metrics()
from lib.metrics import calculate_rolling_metrics

rolling = calculate_rolling_metrics(
    returns=returns_series,
    window=63,  # 3 months
    metrics=['sharpe_ratio', 'max_drawdown']
)

# Access rolling metrics
rolling_sharpe = rolling['sharpe_ratio']
rolling_dd = rolling['max_drawdown']

# ❌ BAD - Manual rolling calculation
rolling_sharpe = returns.rolling(63).apply(lambda x: x.mean() / x.std())
# Incomplete and error-prone!
```

## Metric Validation

### Validate Calculated Metrics
Always validate metrics are within reasonable ranges.

```python
# ✅ GOOD - Validate metrics
from lib.validation import verify_metrics_calculation

metrics = calculate_metrics(returns, transactions)
is_valid, discrepancies = verify_metrics_calculation(
    metrics=metrics,
    returns=returns,
    transactions=transactions
)

if not is_valid:
    for issue in discrepancies:
        print(f"Metric issue: {issue}")
    raise ValueError("Invalid metrics calculated")

# ❌ BAD - Use metrics without validation
metrics = calculate_metrics(returns)
sharpe = metrics['sharpe_ratio']  # May be invalid!
```

## Metrics with Transactions

### Include Transactions for Trade Metrics
Always provide transactions DataFrame when available.

```python
# ✅ GOOD - Include transactions for complete metrics
from lib.backtest import run_backtest
from lib.metrics import calculate_metrics

perf, _ = run_backtest('btc_sma_cross', ...)
transactions_df = perf['transactions'] if 'transactions' in perf.columns else None

metrics = calculate_metrics(
    returns=perf['returns'],
    transactions=transactions_df  # Enables trade metrics
)

# Trade metrics now available
print(f"Trade Count: {metrics['trade_count']}")
print(f"Win Rate: {metrics['win_rate']:.1%}")

# ❌ BAD - Exclude transactions
metrics = calculate_metrics(returns=perf['returns'])
# Missing trade-level insights!
```

## Benchmark Comparison

### Include Benchmark Returns
Provide benchmark returns for relative performance metrics.

```python
# ✅ GOOD - Include benchmark for alpha/beta
from lib.metrics import calculate_metrics

metrics = calculate_metrics(
    returns=strategy_returns,
    benchmark_returns=benchmark_returns,  # S&P 500, etc.
    risk_free_rate=0.04
)

# Relative metrics available
print(f"Alpha: {metrics['alpha']:.2%}")
print(f"Beta: {metrics['beta']:.2f}")

# ❌ BAD - No benchmark comparison
metrics = calculate_metrics(returns=strategy_returns)
# Missing alpha/beta metrics!
```

## Enforcement

- **Code Review**: Verify use of `calculate_metrics()` and related functions
- **Parameter Validation**: Check all required parameters provided
- **Metric Validation**: Ensure metrics validated before use
- **Transaction Inclusion**: Verify transactions included when available

## Related Agents

- `.claude/agents/analyst.md` - Metrics analysis
- `.claude/agents/backtest-runner.md` - Metrics calculation
- `lib/metrics/` - Metrics module documentation
