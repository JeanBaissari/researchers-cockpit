---
description: Optimization patterns - grid_search, random_search, split_data, overfit detection
globs: lib/optimize/**/*.py,scripts/run_optimization.py
alwaysApply: false
---

# Optimization Patterns

## Purpose
Define patterns for parameter optimization using `lib/optimize/` modules, including grid_search, random_search, split_data, and overfit detection.

## Grid Search Optimization

### Use grid_search() Function
Always use `lib.optimize.grid_search()` for exhaustive parameter optimization.

```python
# ✅ GOOD - Use grid_search()
from lib.optimize import grid_search

results = grid_search(
    strategy_name='btc_sma_cross',
    param_grid={
        'strategy.fast_period': [5, 10, 15, 20],
        'strategy.slow_period': [30, 50, 100]
    },
    start_date='2020-01-01',
    end_date='2024-01-01',
    objective='sharpe',
    train_pct=0.7
)

# Find best parameters
best_idx = results['test_sharpe'].idxmax()
best_params = results.loc[best_idx]

# ❌ BAD - Manual parameter testing
for fast in [5, 10, 15]:
    for slow in [30, 50, 100]:
        # Manual backtest...  # Don't do this!
```

### Grid Search Parameters

```python
# ✅ GOOD - Complete parameter specification
results = grid_search(
    strategy_name='spy_sma_cross',
    param_grid={
        'strategy.fast_period': [5, 10, 15],
        'strategy.slow_period': [30, 50, 100]
    },
    start_date='2020-01-01',    # Required
    end_date='2024-01-01',      # Required
    objective='sharpe',          # 'sharpe', 'sortino', 'total_return', 'calmar'
    train_pct=0.7,              # 70% train, 30% test
    capital_base=100000,         # Optional
    bundle='yahoo_equities_daily',  # Optional
    asset_class='equities'       # Optional
)

# ❌ BAD - Missing required parameters
results = grid_search('spy_sma_cross', param_grid={...})  # Missing dates!
```

## Random Search Optimization

### Use random_search() Function
Use `lib.optimize.random_search()` for randomized parameter exploration.

```python
# ✅ GOOD - Use random_search()
from lib.optimize import random_search
import numpy as np

results = random_search(
    strategy_name='btc_sma_cross',
    param_distributions={
        'strategy.fast_period': [5, 10, 15, 20, 25],
        'strategy.slow_period': np.arange(30, 100, 10),
        'strategy.threshold': (0.01, 0.05)  # Uniform range
    },
    n_iter=100,
    objective='sharpe',
    train_pct=0.7
)

# ❌ BAD - Manual random sampling
import random
for _ in range(100):
    fast = random.choice([5, 10, 15])
    # Manual backtest...  # Don't do this!
```

### Parameter Distributions

```python
# ✅ GOOD - Use appropriate distribution types
from lib.optimize import random_search
import numpy as np

results = random_search(
    strategy_name='spy_sma_cross',
    param_distributions={
        # List: Random choice
        'strategy.fast_period': [5, 10, 15, 20],
        # Array: Random choice
        'strategy.slow_period': np.arange(30, 100, 10),
        # Tuple: Uniform range (min, max)
        'strategy.threshold': (0.01, 0.05)
    },
    n_iter=100
)

# ❌ BAD - Invalid distribution format
param_distributions={
    'strategy.fast_period': '5,10,15'  # String, not list!
}
```

## Data Splitting

### Use split_data() Function
Always use `lib.optimize.split_data()` for train/test splitting.

```python
# ✅ GOOD - Use split_data()
from lib.optimize import split_data

train_dates, test_dates = split_data(
    start_date='2020-01-01',
    end_date='2024-01-01',
    train_pct=0.7
)

train_start, train_end = train_dates
test_start, test_end = test_dates

# ❌ BAD - Manual date splitting
split_point = '2023-01-01'  # Hardcoded split!
train_end = split_point
test_start = split_point
```

## Overfit Detection

### Use calculate_overfit_score() Function
Always calculate overfit score after optimization.

```python
# ✅ GOOD - Calculate overfit score
from lib.optimize import grid_search, calculate_overfit_score

results = grid_search(...)

# Calculate overfit probability
overfit_score = calculate_overfit_score(
    in_sample_metrics=results[['train_sharpe']],
    out_sample_metrics=results[['test_sharpe']]
)

if overfit_score['overfit_probability'] > 0.4:
    print("Warning: High overfit probability!")
    print("Consider simplifying strategy or using more data")

# ❌ BAD - Ignore overfitting
results = grid_search(...)
best = results.loc[results['test_sharpe'].idxmax()]
# No overfit check!
```

## Optimization Results Handling

### Save Optimization Results
Always save optimization results using `save_optimization_results()`.

```python
# ✅ GOOD - Save optimization results
from lib.optimize import grid_search, save_optimization_results

results = grid_search(...)
best_params = results.loc[results['test_sharpe'].idxmax()].to_dict()

result_dir = save_optimization_results(
    strategy_name='btc_sma_cross',
    results_df=results,
    best_params=best_params,
    param_grid=param_grid,
    objective='sharpe'
)

# ❌ BAD - Don't save results
results = grid_search(...)
# Results lost after script ends!
```

## Objective Metrics

### Choose Appropriate Objective
Select objective metric based on strategy goals.

```python
# ✅ GOOD - Use appropriate objective
# For risk-adjusted returns
results = grid_search(..., objective='sharpe')

# For downside risk focus
results = grid_search(..., objective='sortino')

# For absolute returns
results = grid_search(..., objective='total_return')

# For drawdown focus
results = grid_search(..., objective='calmar')

# ❌ BAD - Always use default
results = grid_search(...)  # May not match strategy goals!
```

## Enforcement

- **Code Review**: Verify use of optimization functions
- **Overfit Check**: Ensure overfit score calculated
- **Result Saving**: Verify optimization results saved
- **Parameter Validation**: Check parameter distributions valid

## Related Agents

- `.claude/agents/optimizer.md` - Optimization patterns
- `.claude/agents/validator.md` - Overfit validation
- `lib/optimize/` - Optimization module documentation
